{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0adf9168-cdd9-491f-9f81-53ef2782a189",
   "metadata": {},
   "source": [
    "# 실습 목표  \n",
    "\n",
    "main.ipynb를 작성하여 eval dataset에 대해서 PESQ 1.3 이상 달성  \n",
    "\n",
    "\n",
    "# 시작하기   \n",
    "**_[Run]_** 항목은 추가 구현 없이 실행      \n",
    "**_[Run]_** 항목은 구현 하여 실행  \n",
    "**_[Option]_** 항목은 필수적으로 구현할 필요는 없으나 필요시 구현  \n",
    "\n",
    "\n",
    "### clean 데이터\n",
    "+ [AI HUB 한국어 음성 데이터](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=123)  \n",
    "2명의 화자가 특정 주제에 대해서 자유롭게 발화하는 데이터셋  \n",
    "\n",
    "### noise 데이터\n",
    "+ [CHiME4 background noises](https://spandh.dcs.shef.ac.uk/chime_challenge/CHiME4/data.html#Backgrounds)의 STR  \n",
    "특정 장소(STR : 길가)에서 장시간 녹음한 잡음 데이터  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6c70b6-1d15-4994-9f91-097ad8495aaa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Data & Code download  \n",
    "\n",
    "## 다운받을 데이터 구성  \n",
    "+ train    \n",
    "    매 학습시 새로 합성하는 on-fly로 진행하기 때문에 clean, noise 파일로 구성\n",
    "+ dev  \n",
    "    train,eval과 겹치지 않는 데이터로 합성된 noisy 데이터  \n",
    "+ eval  \n",
    "    dev,eval과 겹치지 않는 데이터로 합성된 noisy 데이터\n",
    "+ src :   \n",
    "    사용될 코드들  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0928bed4-90c2-417b-bbe1-f0fbe8833149",
   "metadata": {},
   "source": [
    "**_[Run]구글 드라이브에서 실습자료 다운로드_**     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b23f7d-8175-4fe9-8a41-6d1c28ad2d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pesq in /home/kbh/.conda/envs/dnn/lib/python3.8/site-packages (0.0.4)\n",
      "Dataset already downloaded.\n"
     ]
    }
   ],
   "source": [
    "!pip install pesq\n",
    "\n",
    "from os.path import exists\n",
    "\n",
    "if not exists(\"SE_dataset.tar\") :\n",
    "    !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='1hSqrUQWbwv-JmWvSbhsziA6-BwW5wFkV -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"1hSqrUQWbwv-JmWvSbhsziA6-BwW5wFkV -O SE_dataset.tar && rm -rf /tmp/cookies.txt\n",
    "    !tar -xf SE_dataset.tar\n",
    "else : \n",
    "    print(\"Dataset already downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cdd0f2-a1e9-477b-bc6e-57b1154f0caf",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace67d14-1178-4691-bbb1-b32c942c6aec",
   "metadata": {},
   "source": [
    "https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0f7a46-199d-4419-9a9b-ce800328f7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed7f6e8-8105-4192-ad68-a7ac4607e235",
   "metadata": {},
   "source": [
    "**_[RUN] 모듈 불러오기_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad206a-1fc6-40de-a7de-7479026a643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.dataset import DatasetMix,DatasetFix\n",
    "from src.UNet import UNet\n",
    "from src.utils import get_output_wav,train,infer\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12781589-c10f-4649-afa8-e94e4588f40e",
   "metadata": {},
   "source": [
    "# Dataset \n",
    "\n",
    "DatasetMix :   \n",
    "개별 clean wav에서 1초 길이를 샘플링, 하나의 긴 noise 파일에서 1초 길이를 샘플링 한 뒤  \n",
    "SNR 0dB ~ 10dB 로 랜덤하게 합성   \n",
    "\n",
    "DatasetFix :  \n",
    "미리 합성된 오디오를 사용  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4800aa68-8e0b-48dd-9be3-a3f42f2456c1",
   "metadata": {},
   "source": [
    "**_[RUN] Dataset 생성_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2dcd73-b3a7-4881-a5a6-df744aa62fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = DatasetMix(\"clean_train\",\"noise_train.wav\")\n",
    "dataset_dev = DatasetFix(\"dev\")\n",
    "dataset_eval = DatasetFix(\"eval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f27de07-df27-4a05-b520-1e302ff9ef70",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Implementation\n",
    "\n",
    "## UNet\n",
    "\n",
    "![image.png](https://drive.google.com/uc?id=11liiywXpjgAn96o6ccDLZVO5QtCzBkBX)  \n",
    "\n",
    "위 그림은 참고용 UNet 구조 예시이다.  \n",
    "+ UNet은 Encoder를 통해 입력을 압축하고 Decoder를 통해 원래 차원으로 복원한다.     \n",
    "+ 각 층에서의 Encoder 출력을 대응되는 층의 Decoder 단에서 concat되어서 Decoder의 입력으로 사용된다.   \n",
    "  => Encoder의 출력의 크기는 대응 되는 Decoder 층의 이전 Decoder의 출력과 같아야한다.  \n",
    "+ concat되는 데이터는 Residual path를 사용하여 레이어를 거칠 수도 있고, skip connection으로 아무런 조작없이 사용할 수도 있다.    \n",
    "+ Encoder의 끝과 Decoder의 시작 사이에 bottleneck 레이러를 두기도 한다.  \n",
    "\n",
    "### Input  \n",
    "\n",
    "+ D. S. Williamson, Y. Wang and D. Wang, \"Complex Ratio Masking for Monaural Speech Separation,\" in IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 24, no. 3, pp. 483-492, March 2016, doi: 10.1109/TASLP.2015.2512042.  \n",
    "![image.png](https://drive.google.com/uc?id=1jWyLRn4WqKVi7PqtFIVzf4o1kbJJ3tIE)   \n",
    "\n",
    "noisy를 STFT 취한뒤, complex domain에서 magnitude를 입력으로 사용한다.\n",
    "phase 성분은 위 그림처럼 제대로 정보를 취득하기 어렵기 때문에 본 실습에서는 사용하지 않는다.  \n",
    "\n",
    "\n",
    "### Output  \n",
    "\n",
    "magnitude의 Mask를 모델의 출력으로 사용한다. 입력의 magnitude에 생성된 마스크를 사용하여 잡음을 제거하고  \n",
    "입력의 phase를 사용하여 WAV 신호로 복원한다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b2569f-3153-45cc-ad2d-a9e5a0893dab",
   "metadata": {},
   "source": [
    "**_[TODO]Encoder,Decoder 구현_**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e5c63b-1b48-4c50-9a3f-ebfb6fb498ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Encoder\n",
    "\n",
    "\n",
    "![image.png](https://drive.google.com/uc?id=1yhiWPvBizH4dVdnHz5MZkv5XEH4xPiVq)  \n",
    "Conv2d(Convolution) <-> ConvTranspose2d(Deconvolution)  \n",
    "\n",
    "기본적인 Encoder,Decoder 모듈은 제공  \n",
    "encoder,decoder list 에 같은 갯수의 Encoder,Decoder를 쌓아서 UNet을 구성  \n",
    "+ 모듈 쌓기   \n",
    "+ 모듈 수정하기\n",
    "+ 모듈ㅇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dba566c-05d7-4882-aac5-ea577a7785ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 out_channels, \n",
    "                 kernel_size, \n",
    "                 stride, \n",
    "                 padding):\n",
    "        super().__init__()\n",
    "      \n",
    "        self.conv = nn.Conv2d(in_channels, \n",
    "                              out_channels, \n",
    "                              kernel_size=kernel_size, \n",
    "                              stride=stride,\n",
    "                              padding=padding)\n",
    "        self.norm = nn.BatchNorm2d(out_channels)\n",
    "        self.acti = nn.LeakyReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.acti(x)\n",
    "        return x\n",
    "\n",
    "encoders=[]\n",
    "print(len(encoders))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d622ed-34d5-45e4-b717-f704de37cda1",
   "metadata": {},
   "source": [
    "## Decoder  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642e8f04-e571-4a3f-8534-3a8c141c0a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 out_channels,\n",
    "                 kernel_size, \n",
    "                 stride, \n",
    "                 output_padding,\n",
    "                 padding=(0, 0)):\n",
    "        super().__init__()\n",
    "       \n",
    "        self.transconv = nn.ConvTranspose2d(\n",
    "            in_channels, \n",
    "            out_channels, \n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride, \n",
    "            output_padding=output_padding,\n",
    "            padding=padding)\n",
    "        self.norm = nn.BatchNorm2d(out_channels)\n",
    "        self.acti = nn.LeakyReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transconv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.acti(x)\n",
    "        return x\n",
    "    \n",
    "decoders=[]\n",
    "print(len(decoders))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49db875-ecbf-429f-927a-8288b14c14f7",
   "metadata": {},
   "source": [
    "**_[Option]Residual Path,bottleneck 구현_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6ff478-743f-469c-84a3-e7acad5e075b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8762a8-c8d8-49e5-974b-22ca0b192c5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d27882b-af15-4790-8090-f7c1e5e1c6aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9917dd00-54b7-46e7-8f09-5a2db4a8aa45",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Residual Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de1b1c1-bdb6-4fe9-b29b-dedae34938fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3faa07a-14c9-45dd-b75a-26681602ad07",
   "metadata": {
    "tags": []
   },
   "source": [
    "## UNet\n",
    "\n",
    "**_[RUN]모델 정상 동작 확인_**  \n",
    ": 에러가 발생하지 않아야한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008e81f9-68c1-456d-9bcd-bcdff21b5d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(encoders,decoders)\n",
    "x = torch.rand(1,1,257,126)\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee981ac0-2b33-43a5-9084-810cb0ae0904",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SDR(Signal-to-Distortion Ratio) Loss\n",
    "\n",
    "+ Venkataramani, Shrikant, Jonah Casebeer, and Paris Smaragdis. \"Adaptive front-ends for end-to-end source separation.\" Proc. NIPS. 2017.  \n",
    "+ Choi, Hyeong-Seok, et al. \"Phase-aware speech enhancement with deep complex u-net.\" International Conference on Learning Representations. 2018.  \n",
    "\n",
    "![image.png](https://drive.google.com/uc?id=1bis4FlepY8H9TULmapLEX7XU9QcL5Iqi)\n",
    "\n",
    "\n",
    "## TODO  \n",
    "\n",
    "SDR에 관한 수학적 이야기 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a683430-8d42-478a-baac-632134bed143",
   "metadata": {},
   "source": [
    "**_[TODO]mSDRLoss 구현_**     \n",
    ": (6) 식 구현\n",
    "\n",
    "+ 참고    \n",
    "  TODO : 몇가지 torch linalg 함수들 .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fc2fdd8-d6ee-4b60-a91d-0037a256a768",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    x     : noisy = y+z\n",
    "    y     : clean\n",
    "    y_hat : estimated clean \n",
    "    z     : noise\n",
    "    z_hat : estimated noise\n",
    "\"\"\"\n",
    "\n",
    "def mSDRLoss(y,y_hat, eps=1e-7):\n",
    "    ## mSDRLoss 구현\n",
    "    \n",
    "    return mSDR\n",
    "\n",
    "def wSDRLoss(y,x,y_hat,alpha=0.1,eps=1e-7):\n",
    "        z = x - y\n",
    "        z_hat = x - y_hat\n",
    "\n",
    "        wSDR = alpha * mSDRLoss(y,y_hat,eps=eps) + (1-alpha)*mSDRLoss(z,z_hat,eps=eps)\n",
    "        return wSDR\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb2fbe0-51a0-4dea-84e1-1d8871dc246a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train\n",
    "\n",
    "**_[TODO]학습 진행_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dacb845f-2379-4e99-a317-131b51b0013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model,dataset_train,dataset_dev,wSDRLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d011ce-3e4e-416d-a7c6-0ca6119eef08",
   "metadata": {},
   "source": [
    "## Visualization  \n",
    "**_[Run]모델 출력 시각화_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba16dd2b-7bc0-4785-833f-693bb807fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to visualize\n",
    "idx = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    clean,noisy,estim = infer(dataset_eval[idx],model)\n",
    "    \n",
    "    ipd.display(ipd.Markdown('+ clean'))\n",
    "    display(ipd.Audio(clean,rate=16000))\n",
    "    \n",
    "    plot_spec(clean,\"clean\")\n",
    "    plot_spec(noisy,\"noisy\")\n",
    "    plot_spec(estim,\"estim\")\n",
    "    \n",
    "    ipd.display(ipd.Markdown('+ noisy'))\n",
    "    display(ipd.Audio(noisy,rate=16000))\n",
    "    \n",
    "    ipd.display(ipd.Markdown('+ estim'))\n",
    "    display(ipd.Audio(estim,rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45a5ac5-2aa6-4f31-b2e8-97c2c7f51daa",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "PESQ 설명  \n",
    "\n",
    "**_[TODO] PESQ 1.3 이상 달성_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504901af-95ca-4ab5-a6d6-15fdfcb41a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import infer,plot_spec\n",
    "\n",
    "from pesq import pesq\n",
    "from pesq import NoUtterancesError                         \n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():    \n",
    "    d = 0\n",
    "    n = 0\n",
    "    cnt = 0\n",
    "    for i in tqdm(range(len(dataset_eval))) :\n",
    "        clean,noisy,estim = infer(dataset_eval[i],model)\n",
    "        try : \n",
    "            n+= pesq(16000,clean, noisy, \"wb\")\n",
    "            d += pesq(16000,clean, estim, \"wb\")\n",
    "            cnt+=1\n",
    "        except NoUtterancesError : \n",
    "            continue\n",
    "    d /=cnt\n",
    "    n /=cnt\n",
    "    print(n)\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d9472d-149b-491a-b32a-df9aeded7b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
